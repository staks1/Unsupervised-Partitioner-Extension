{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-06-25T11:18:15.046693Z","iopub.execute_input":"2023-06-25T11:18:15.047107Z","iopub.status.idle":"2023-06-25T11:18:27.049351Z","shell.execute_reply.started":"2023-06-25T11:18:15.047075Z","shell.execute_reply":"2023-06-25T11:18:27.048193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/models /kaggle/working/tensors","metadata":{"execution":{"iopub.status.busy":"2023-06-25T11:18:32.822282Z","iopub.execute_input":"2023-06-25T11:18:32.823219Z","iopub.status.idle":"2023-06-25T11:18:33.771496Z","shell.execute_reply.started":"2023-06-25T11:18:32.823183Z","shell.execute_reply":"2023-06-25T11:18:33.770212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/input/neural-partitioner-dsit","metadata":{"execution":{"iopub.status.busy":"2023-06-25T11:18:36.750625Z","iopub.execute_input":"2023-06-25T11:18:36.751016Z","iopub.status.idle":"2023-06-25T11:18:36.760602Z","shell.execute_reply.started":"2023-06-25T11:18:36.750983Z","shell.execute_reply":"2023-06-25T11:18:36.759235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using three kinds of *partitioning schemes*, for both **fashion-mnist** and **sift** datasets, with the paper's orinal experimental setup plus some extras (PCA, Mahalanobis distance, a CNN architecture and a multi-model Ensembling)","metadata":{}},{"cell_type":"markdown","source":"### **Fashion Mnist dataset**","metadata":{}},{"cell_type":"markdown","source":"#### *16-bin partition using a simple NN as a first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 16 --dataset_name mnist --n_trees 3 --n_bins_to_search 3 --eta_value 7 --pca_comp 0.95 --lr 0.009 > /kaggle/working/pca-16-mnist.txt 2>&1","metadata":{"execution":{"iopub.status.busy":"2023-06-24T14:56:17.994283Z","iopub.execute_input":"2023-06-24T14:56:17.995082Z","iopub.status.idle":"2023-06-24T15:08:33.233630Z","shell.execute_reply.started":"2023-06-24T14:56:17.995041Z","shell.execute_reply":"2023-06-24T15:08:33.232375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 20 --k_test 10 --n_epochs 80 --model_type neural --n_bins 16 --dataset_name mnist --n_trees 3 --n_bins_to_search 3 --eta_value 7 --distance_metric mahalanobis --lr 0.009 > /kaggle/working/mahalanobis-16-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using a convolutional neural network\n!python main.py --k_train 20 --k_test 10 --n_epochs 5 --model_type cnn --n_bins 16 --dataset_name mnist --n_trees 3 --n_bins_to_search 3 --eta_value 7 --lr 0.009 > /kaggle/working/cnn-16-mnist.txt 2>&1","metadata":{"execution":{"iopub.status.busy":"2023-06-24T14:54:16.645657Z","iopub.execute_input":"2023-06-24T14:54:16.646045Z","iopub.status.idle":"2023-06-24T14:54:19.604327Z","shell.execute_reply.started":"2023-06-24T14:54:16.646014Z","shell.execute_reply":"2023-06-24T14:54:19.602950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 5 --model_combination cnn neural linear --n_bins 16 --dataset_name mnist --n_trees 3 --n_bins_to_search 3 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-16-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *256-bin partition using a simple NN as the first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 20 --k_test 10 --n_epochs 80 --model_type neural --n_bins 256 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 30 --pca_comp 0.95 --lr 0.009 > /kaggle/working/pca-256-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 20 --k_test 10 --n_epochs 80 --model_type neural --n_bins 256 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 30 --distance_metric mahalanobis --lr 0.009 > /kaggle/working/mahalanobis-256-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using a convolutional neural network\n!python main.py --k_train 10 --k_test 10 --n_epochs 10 --n_bins 256 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 30 --model_type cnn --lr 0.009 > /kaggle/working/cnn-256-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 5 --model_combination cnn neural linear --n_bins 256 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-256-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *1024-bin partition using Linear Regression as the first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 20 --k_test 10 --n_epochs 80 --model_type neural --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 30 --pca_comp 0.95 --lr 0.009 > /kaggle/working/pca-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 2 --distance_metric mahalanobis --lr 0.009 > /kaggle/working/mahalanobis-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using a convolutional neural network\n!python main.py --k_train 10 --k_test 10 --n_epochs 20 --model_type cnn --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 20 --lr 0.009 > /kaggle/working/cnn-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 15 --model_combination cnn neural linear --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Sift dataset**\n\nCNNs were not used for this dataset. CNNs typically take raw images as input and expect a fixed input shape (e.g., 224x224x3 for color images). SIFT features are usually not in this format; and no effort, in finding a way to reshape or represent them in a way that can be input into a CNN was made. ","metadata":{}},{"cell_type":"markdown","source":"#### *16-bin partition using a simple NN as a first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 16 --dataset_name sift --n_trees 3 --n_bins_to_search 3 --eta_value 7 --pca_comp 0.95 --lr 0.0009 > /kaggle/working/pca-16-sift.txt 2>&1","metadata":{"execution":{"iopub.status.busy":"2023-06-24T14:56:17.994283Z","iopub.execute_input":"2023-06-24T14:56:17.995082Z","iopub.status.idle":"2023-06-24T15:08:33.233630Z","shell.execute_reply.started":"2023-06-24T14:56:17.995041Z","shell.execute_reply":"2023-06-24T15:08:33.232375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 16 --dataset_name sift --n_trees 3 --n_bins_to_search 3 --eta_value 7 --distance_metric mahalanobis --lr 0.0009 > /kaggle/working/mahalanobis-16-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 5 --model_combination linear neural linear --n_bins 16 --dataset_name sift --n_trees 3 --n_bins_to_search 3 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-16-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *256-bin partition using a simple NN as a first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 256 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 10 --pca_comp 0.95 --lr 0.0009 > /kaggle/working/pca-256-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 256 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 10 --distance_metric mahalanobis --lr 0.0009 > /kaggle/working/mahalanobis-256-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 15 --model_combination linear neural linear --n_bins 256 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-256-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *1024-bin partition using Linear Regression as a first ensembling model*","metadata":{}},{"cell_type":"code","source":"# Using PCA with 95% retained variance\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 1024 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 10 --pca_comp 0.95 --lr 0.0009 > /kaggle/working/pca-1024-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Mahalanobis distance metric\n!python main.py --k_train 10 --k_test 10 --n_epochs 80 --model_type neural --n_bins 1024 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 10 --distance_metric mahalanobis --lr 0.0009 > /kaggle/working/mahalanobis-1024-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the ensembling of different models\n!python main.py --k_train 10 --k_test 10 --n_epochs 20 --model_combination linear neural linear --n_bins 1024 --dataset_name sift --n_trees 3 --n_bins_to_search 6 --eta_value 2 --lr 0.009 > /kaggle/working/ensembling-1024-sift.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Runs from original paper","metadata":{}},{"cell_type":"code","source":"#!python main.py --k_train 10 --k_test 10 --n_epochs 20 --n_bins 16 --dataset_name mnist --n_trees 3 --n_bins_to_search 2 --eta_value 7 --model_type neural > /kaggle/working/original-16-mnist.txt 2>&1","metadata":{"execution":{"iopub.status.busy":"2023-06-25T06:21:57.189063Z","iopub.execute_input":"2023-06-25T06:21:57.189617Z","iopub.status.idle":"2023-06-25T06:27:25.453705Z","shell.execute_reply.started":"2023-06-25T06:21:57.189570Z","shell.execute_reply":"2023-06-25T06:27:25.452272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python main.py --k_train 10 --k_test 10 --n_epochs 60 --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 10 --model_type neural > /kaggle/working/original-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python main.py --k_train 10 --k_test 10 --n_epochs 60 --n_bins 1024 --dataset_name mnist --n_trees 3 --n_bins_to_search 6 --eta_value 10 --model_type neural > /kaggle/working/original-1024-mnist.txt 2>&1","metadata":{},"execution_count":null,"outputs":[]}]}